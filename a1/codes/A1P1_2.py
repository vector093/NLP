# -*- coding: utf-8 -*-
"""A1P1_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wao8AFKWr8EI1a4RxeWf2_BgjBSUHT1Q
"""

import torch
import torchtext

# The first time you run this will download a ~823MB file
glove = torchtext.vocab.GloVe(name="6B", # trained on Wikipedia 2014 corpus
                              dim=50)    # embedding size = 50

def print_closest_cosine_words(vec, n=5):
  # vec is the embedding vector of the word
  dists = torch.cosine_similarity(glove.vectors.unsqueeze(0), vec.unsqueeze(0), dim=2).squeeze()
  dist_sort=torch.argsort(dists,descending=True)
  for idx in dist_sort[1:n+1]:
    print(glove.itos[idx], "\t%5.2f" % dists[idx])
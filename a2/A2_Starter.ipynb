{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torchtext\n", "from torchtext import data\n", "import torch.optim as optim\n", "import argparse\n", "import os\n", "import pandas as pd"]}, {"cell_type": "markdown", "metadata": {}, "source": ["TextDataset is Described in Section 3.3 of Assignment 2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class TextDataset(torch.utils.data.Dataset):\n", "    def __init__(self, vocab, split=\"train\"):\n", "        data_path = \"data\"\n", "        df = pd.read_csv(os.path.join(data_path, f\"{split}.tsv\"), sep=\"\\t\")\n\n", "        # X: torch.tensor (maxlen, batch_size), padded indices\n", "        # Y: torch.tensor of len N\n", "        X, Y = [], []\n", "        V = len(vocab.vectors)\n", "        for i, row in df.iterrows():\n", "            L = row[\"text\"].split()\n", "            X.append(torch.tensor([vocab.stoi.get(w, V-1) for w in L]))  # Use the last word in the vocab as the \"out-of-vocabulary\" token\n", "            Y.append(row.label)\n", "        self.X = X \n", "        self.Y = torch.tensor(Y)\n", "        \n", "    def __len__(self):\n", "        return len(self.X)\n", "    def __getitem__(self, idx):\n", "        return self.X[idx], self.Y[idx] \n", "    \n", "# my_collate_function prepares batches\n", "# it also pads each batch with zeroes."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def my_collate_function(batch, device):\n", "    # Handle the padding here\n", "    # batch is approximately: [dataset[i] for i in range(0, batch_size)]\n", "    # Since the dataset[i]'s contents is defined in the __getitem__() above, this collate function \n", "    # should be set correspondingly.\n", "    # Also: collate_function just takes one argument. To pass in additional arguments (e.g., device), \n", "    # we need to wrap up an anonymous function (using lambda below)\n", "    batch_x, batch_y = [], []\n", "    max_len = 0\n", "    for x,y in batch:\n", "        batch_y.append(y)\n", "        max_len = max(max_len, len(x))\n", "    for x,y in batch:\n", "        x_p = torch.concat(\n", "            [x, torch.zeros(max_len - len(x))]\n", "        )\n", "        batch_x.append(x_p)\n", "    return torch.stack(batch_x).t().int().to(device), torch.tensor(batch_y).to(device)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main(args):\n", "    #   fix seed\n", "    torch.manual_seed(2)\n", "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "    print (\"Using device:\", device)\n\n", "    ### 3.3 Processing of the data ###\n", "    # 3.3.1\n", "    # The first time you run this will download a 862MB size file to .vector_cache/glove.6B.zip\n", "    glove = torchtext.vocab.GloVe(name=\"6B\",dim=100) # embedding size = 100\n", "                                   \n", "    # 3.3.2\n", "    train_dataset = TextDataset(glove, \"train\")\n", "    val_dataset = TextDataset(glove, \"validation\")\n", "    test_dataset = TextDataset(glove, \"test\")\n", "        \n", "    # 3.3.3\n", "    train_dataloader = torch.utils.data.DataLoader(\n", "        dataset=train_dataset, \n", "        batch_size=args.batch_size, \n", "        shuffle=False, \n", "        collate_fn=lambda batch: my_collate_function(batch, device))\n", "    validation_dataloader = torch.utils.data.DataLoader(\n", "        dataset=val_dataset, \n", "        batch_size=args.batch_size, \n", "        shuffle=False, \n", "        collate_fn=lambda batch: my_collate_function(batch, device))\n", "    test_dataloader = torch.utils.data.DataLoader(\n", "        dataset=test_dataset,\n", "        batch_size=args.batch_size,\n", "        shuffle=False,\n", "        collate_fn=lambda batch: my_collate_function(batch, device))\n\n", "    # Instantiate your model(s) and train them and so on \n", "    # We suggest parameterizing the model - k1, n1, k2, n2, and other hyperparameters\n", "    # so that it is easier to experiment with\n", "    \n", "    \n", "   "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # baseline model\n",
    " # It first converts each of the word tokens into a vector using the GloVe word embeddings that were downloaded. It then computes \n",
    " # the average of those word embeddings in a given sentence. The idea is that this becomes the ‘average’ meaning of the entire \n",
    " # sentence. This is fed to a fully connected layer which produces a scalar output with sigmoid activation (which should be computed \n",
    " # inside the BCEWithLogitsLoss losss function) to represent the probability that the sentence is in the subjective class.\n",
    "class Baseline(torch.nn.Module):\n",
    "\tdef __init__(self, glove):\n",
    "\t\tsuper(Baseline, self).__init__()\n",
    "\t\tself.embedding = torch.nn.Embedding.from_pretrained(glove.vectors)\n",
    "\t\tself.fc = torch.nn.Linear(100, 1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.embedding(x)\n",
    "\t\tx = torch.mean(x, dim=0)\n",
    "\t\tx = self.fc(x).squeeze()\n",
    "\t\treturn x\n",
    "\n",
    "# cnn model\n",
    "class CNN(nn.Module):\n",
    "\tdef __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\t\tself.convs = nn.ModuleList([\n",
    "\t\tnn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (fs, embedding_dim)) for fs in filter_sizes\n",
    "\t\t])\n",
    "\t\tself.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\t\n",
    "\tdef forward(self, text):\n",
    "\t\t#text = [sent len, batch size]\n",
    "\t\ttext = text.permute(1, 0)\n",
    "\t\t#text = [batch size, sent len]\n",
    "\t\tembedded = self.embedding(text)\n",
    "\t\t#embedded = [batch size, sent len, emb dim]\n",
    "\t\tembedded = embedded.unsqueeze(1)\n",
    "\t\t#embedded = [batch size, 1, sent len, emb dim]\n",
    "\t\tconved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "\t\t#conv_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "\t\tpooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "\t\t#pooled_n = [batch size, n_filters]\n",
    "\t\tcat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\t\t#cat = [batch size, n_filters * len(filter_sizes)]\n",
    "\t\treturn self.fc(cat)\n",
    "\n",
    "glove = torchtext.vocab.GloVe(name=\"6B\",dim=100)\n",
    "INPUT_DIM = len(glove.vectors)\n",
    "EMBEDDING_DIM = 100\n",
    "N_FILTERS = 50\n",
    "FILTER_SIZES = [2,4]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(400000, 100)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 50, kernel_size=(2, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 50, kernel_size=(4, 100), stride=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load baseline model from saved checkpoint\n",
    "baseline_model = Baseline(glove)\n",
    "baseline_model.load_state_dict(torch.load('baseline.pt'))\n",
    "baseline_model.eval()\n",
    "\n",
    "# load cnn model from saved checkpoint\n",
    "cnn_model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
    "cnn_model.load_state_dict(torch.load('cnn.pt', map_location=torch.device('cpu')))\n",
    "cnn_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x124cecc70>, 'http://127.0.0.1:7860/', None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline prediction function with output probability and label\n",
    "def baseline_predict(sentence):\n",
    "\ttokens = sentence.split()\n",
    "\t# Convert to integer representation per token\n",
    "\ttoken_ints = [glove.stoi.get(tok, len(glove.stoi)-1) for tok in tokens]\n",
    "\t# Convert into a tensor of the shape accepted by the models\n",
    "\ttoken_tensor = torch.LongTensor(token_ints).view(-1,1)\n",
    "\t# Get the output from the model\n",
    "\tprediction = baseline_model(token_tensor)\n",
    "\tprediction = torch.sigmoid(prediction)\n",
    "\tprediction = prediction.item()\n",
    "\tif prediction > 0.5:\n",
    "\t\treturn prediction, \"Subjective\"\n",
    "\telse:\n",
    "\t\treturn prediction, \"Objective\"\n",
    "\n",
    "# cnn prediction function with output probability and label\n",
    "def cnn_predict(sentence):\n",
    "\t# pad the sentence to atleast 4 words\n",
    "\tif len(sentence.split()) < 4:\n",
    "\t\tsentence += \" . . .\"\n",
    "\ttokens = sentence.split()\n",
    "\t# Convert to integer representation per token\n",
    "\ttoken_ints = [glove.stoi.get(tok, len(glove.stoi)-1) for tok in tokens]\n",
    "\t# Convert into a tensor of the shape accepted by the models\n",
    "\ttoken_tensor = torch.LongTensor(token_ints).view(-1,1)\n",
    "\t# Get the output from the model\n",
    "\tprediction = cnn_model(token_tensor)\n",
    "\tprediction = torch.sigmoid(prediction)\n",
    "\tprediction = prediction.item()\n",
    "\tif prediction > 0.5:\n",
    "\t\treturn prediction, \"Subjective\"\n",
    "\telse:\n",
    "\t\treturn prediction, \"Objective\"\n",
    "\n",
    "# baseline interface\n",
    "baseline_interface = gr.Interface(fn=baseline_predict, inputs=\"text\", outputs= [gr.outputs.Textbox(label=\"Baseline Probability\"), gr.outputs.Textbox(label=\"Baseline Label\")], title=\"Baseline Model\", description=\"Enter a sentence to predict whether it is subjective or objective\", allow_flagging=False)\n",
    "\n",
    "\n",
    "# cnn interface\n",
    "cnn_interface = gr.Interface(fn=cnn_predict, inputs=\"text\", outputs=[gr.outputs.Textbox(label=\"CNN Probability\"), gr.outputs.Textbox(label=\"CNN Label\")], title=\"CNN Model\", description=\"Enter a sentence to predict whether it is subjective or objective.\", allow_flagging=False)\n",
    "\n",
    "\n",
    "gr.Parallel(baseline_interface, cnn_interface).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a513deec7106273024eef7febe46d4fe4cdb642620a5b7c4bf01ad189c916154"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
